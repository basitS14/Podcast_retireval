{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab40e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bfb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"episodes-sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0186539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>show_id</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>guid</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>author</th>\n",
       "      <th>audio_url</th>\n",
       "      <th>audio_file_size</th>\n",
       "      <th>audio_mime_type</th>\n",
       "      <th>category</th>\n",
       "      <th>explicit</th>\n",
       "      <th>length</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01154863-5892-3bdb-bd55-969689561906</td>\n",
       "      <td>580ca3d7-1d85-3ef3-a1b4-c6f4edf9ff65</td>\n",
       "      <td>To The Journey 138: George Clooney Found His J...</td>\n",
       "      <td>http://trek.fm/to-the-journey/138</td>\n",
       "      <td>4ff44f9bc4aa4a0dd8ca3ab3:50cd794ae4b08d91f1b65...</td>\n",
       "      <td>Top Five Out-of-Character Moments. From small ...</td>\n",
       "      <td>&lt;h3&gt;Top Five Out-of-Character Moments.&amp;nbsp;&lt;/...</td>\n",
       "      <td>Top Five Out-of-Character Moments.   Whether i...</td>\n",
       "      <td>Trek.fm</td>\n",
       "      <td>http://traffic.libsyn.com/tothejourney/ttj-138...</td>\n",
       "      <td>32657154</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>Voyager</td>\n",
       "      <td>0</td>\n",
       "      <td>2651</td>\n",
       "      <td>2015-09-30 23:44:45 UTC</td>\n",
       "      <td>Podcasts,To,The,Journey,Voyager,Lists,Out-of-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26087c95-f627-30d7-aa8a-9d72daa6d26c</td>\n",
       "      <td>71619835-0783-3d3f-bc4c-850031dd5af8</td>\n",
       "      <td>The World Game Podcast - 4 December</td>\n",
       "      <td>http://feedproxy.google.com/~r/twgpodcast/~3/i...</td>\n",
       "      <td>tag:soundcloud,2010:tracks/69909432</td>\n",
       "      <td>The World Game podcast this week looks at how ...</td>\n",
       "      <td>The World Game podcast this week looks at how ...</td>\n",
       "      <td>The World Game podcast this week looks at how ...</td>\n",
       "      <td>SBS The World Game</td>\n",
       "      <td>http://feedproxy.google.com/~r/twgpodcast/~5/k...</td>\n",
       "      <td>14386269</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1798</td>\n",
       "      <td>2012-12-04 06:11:33 UTC</td>\n",
       "      <td>SBS,TWG,The,World,Game,Soccer,Football,Shootou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6d713bbd-4d96-3ac3-8164-563926963832</td>\n",
       "      <td>9a3d6c76-052e-3f95-9f8b-b0b21b983a02</td>\n",
       "      <td>drunk dripping drunk  (71)</td>\n",
       "      <td>http://shaneandtom.libsyn.com/drunk_dripping_d...</td>\n",
       "      <td>http://shaneandtom.libsyn.com/index.php?post_i...</td>\n",
       "      <td>Don't even ask, just listen and enjoy...or wha...</td>\n",
       "      <td>Don't even ask, just listen and enjoy...or wha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://traffic.libsyn.com/shaneandtom/drunk_dr...</td>\n",
       "      <td>19594870</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2449</td>\n",
       "      <td>2007-04-23 01:59:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0e753ea-28c3-3550-9bc5-519b71c7e462</td>\n",
       "      <td>023e6901-ff34-329d-8954-95ba55ed1c8d</td>\n",
       "      <td>RETURN OF ANCIENT RITUALS...part five, ritual ...</td>\n",
       "      <td>https://www.podomatic.com/podcasts/preemptionb...</td>\n",
       "      <td>http://preemptionbroadcast.podomatic.com/entry...</td>\n",
       "      <td>There is a few moments of skipping in the begi...</td>\n",
       "      <td>There is a few moments of skipping in the begi...</td>\n",
       "      <td>There is a few moments of skipping in the begi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://preemptionbroadcast.podOmatic.com/enclo...</td>\n",
       "      <td>56549074</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3534</td>\n",
       "      <td>2011-09-09 23:29:57 UTC</td>\n",
       "      <td>voodoo,in,white,house,rituals,2012,priestess,s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48d8cbb2-ce14-32a2-b82d-b71891f4eaf4</td>\n",
       "      <td>ef42fe17-8acb-3671-8234-1327242f1cfc</td>\n",
       "      <td>Mac OS Ken: 08.22.2012</td>\n",
       "      <td>http://macosken.libsyn.com/mac-os-ken-08-22-2012</td>\n",
       "      <td>83e3c3caccce9c244cf99a06e85901eb</td>\n",
       "      <td>Apple and Samsung Make Closing Arguments; Case...</td>\n",
       "      <td>Apple and Samsung Make Closing Arguments; Case...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://traffic.libsyn.com/macosken/macosken120...</td>\n",
       "      <td>8372262</td>\n",
       "      <td>audio/mpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>823</td>\n",
       "      <td>2012-08-22 08:41:57 UTC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                               show_id  \\\n",
       "0  01154863-5892-3bdb-bd55-969689561906  580ca3d7-1d85-3ef3-a1b4-c6f4edf9ff65   \n",
       "1  26087c95-f627-30d7-aa8a-9d72daa6d26c  71619835-0783-3d3f-bc4c-850031dd5af8   \n",
       "2  6d713bbd-4d96-3ac3-8164-563926963832  9a3d6c76-052e-3f95-9f8b-b0b21b983a02   \n",
       "3  c0e753ea-28c3-3550-9bc5-519b71c7e462  023e6901-ff34-329d-8954-95ba55ed1c8d   \n",
       "4  48d8cbb2-ce14-32a2-b82d-b71891f4eaf4  ef42fe17-8acb-3671-8234-1327242f1cfc   \n",
       "\n",
       "                                               title  \\\n",
       "0  To The Journey 138: George Clooney Found His J...   \n",
       "1                The World Game Podcast - 4 December   \n",
       "2                         drunk dripping drunk  (71)   \n",
       "3  RETURN OF ANCIENT RITUALS...part five, ritual ...   \n",
       "4                             Mac OS Ken: 08.22.2012   \n",
       "\n",
       "                                                link  \\\n",
       "0                  http://trek.fm/to-the-journey/138   \n",
       "1  http://feedproxy.google.com/~r/twgpodcast/~3/i...   \n",
       "2  http://shaneandtom.libsyn.com/drunk_dripping_d...   \n",
       "3  https://www.podomatic.com/podcasts/preemptionb...   \n",
       "4   http://macosken.libsyn.com/mac-os-ken-08-22-2012   \n",
       "\n",
       "                                                guid  \\\n",
       "0  4ff44f9bc4aa4a0dd8ca3ab3:50cd794ae4b08d91f1b65...   \n",
       "1                tag:soundcloud,2010:tracks/69909432   \n",
       "2  http://shaneandtom.libsyn.com/index.php?post_i...   \n",
       "3  http://preemptionbroadcast.podomatic.com/entry...   \n",
       "4                   83e3c3caccce9c244cf99a06e85901eb   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  Top Five Out-of-Character Moments. From small ...   \n",
       "1  The World Game podcast this week looks at how ...   \n",
       "2  Don't even ask, just listen and enjoy...or wha...   \n",
       "3  There is a few moments of skipping in the begi...   \n",
       "4  Apple and Samsung Make Closing Arguments; Case...   \n",
       "\n",
       "                                         description  \\\n",
       "0  <h3>Top Five Out-of-Character Moments.&nbsp;</...   \n",
       "1  The World Game podcast this week looks at how ...   \n",
       "2  Don't even ask, just listen and enjoy...or wha...   \n",
       "3  There is a few moments of skipping in the begi...   \n",
       "4  Apple and Samsung Make Closing Arguments; Case...   \n",
       "\n",
       "                                             summary              author  \\\n",
       "0  Top Five Out-of-Character Moments.   Whether i...             Trek.fm   \n",
       "1  The World Game podcast this week looks at how ...  SBS The World Game   \n",
       "2                                                NaN                 NaN   \n",
       "3  There is a few moments of skipping in the begi...                 NaN   \n",
       "4                                                NaN                 NaN   \n",
       "\n",
       "                                           audio_url  audio_file_size  \\\n",
       "0  http://traffic.libsyn.com/tothejourney/ttj-138...         32657154   \n",
       "1  http://feedproxy.google.com/~r/twgpodcast/~5/k...         14386269   \n",
       "2  http://traffic.libsyn.com/shaneandtom/drunk_dr...         19594870   \n",
       "3  http://preemptionbroadcast.podOmatic.com/enclo...         56549074   \n",
       "4  http://traffic.libsyn.com/macosken/macosken120...          8372262   \n",
       "\n",
       "  audio_mime_type category  explicit  length                 pub_date  \\\n",
       "0      audio/mpeg  Voyager         0    2651  2015-09-30 23:44:45 UTC   \n",
       "1      audio/mpeg      NaN         0    1798  2012-12-04 06:11:33 UTC   \n",
       "2      audio/mpeg      NaN         0    2449  2007-04-23 01:59:00 UTC   \n",
       "3      audio/mpeg      NaN         0    3534  2011-09-09 23:29:57 UTC   \n",
       "4      audio/mpeg      NaN         0     823  2012-08-22 08:41:57 UTC   \n",
       "\n",
       "                                            keywords  \n",
       "0  Podcasts,To,The,Journey,Voyager,Lists,Out-of-c...  \n",
       "1  SBS,TWG,The,World,Game,Soccer,Football,Shootou...  \n",
       "2                                                NaN  \n",
       "3  voodoo,in,white,house,rituals,2012,priestess,s...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ba2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               50000 non-null  object\n",
      " 1   show_id          50000 non-null  object\n",
      " 2   title            49999 non-null  object\n",
      " 3   link             42341 non-null  object\n",
      " 4   guid             49244 non-null  object\n",
      " 5   subtitle         44460 non-null  object\n",
      " 6   description      45605 non-null  object\n",
      " 7   summary          29609 non-null  object\n",
      " 8   author           30865 non-null  object\n",
      " 9   audio_url        50000 non-null  object\n",
      " 10  audio_file_size  50000 non-null  int64 \n",
      " 11  audio_mime_type  49992 non-null  object\n",
      " 12  category         12337 non-null  object\n",
      " 13  explicit         50000 non-null  int64 \n",
      " 14  length           50000 non-null  int64 \n",
      " 15  pub_date         49945 non-null  object\n",
      " 16  keywords         24212 non-null  object\n",
      "dtypes: int64(3), object(14)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9303f0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "show_id                0\n",
       "title                  1\n",
       "link                7659\n",
       "guid                 756\n",
       "subtitle            5540\n",
       "description         4395\n",
       "summary            20391\n",
       "author             19135\n",
       "audio_url              0\n",
       "audio_file_size        0\n",
       "audio_mime_type        8\n",
       "category           37663\n",
       "explicit               0\n",
       "length                 0\n",
       "pub_date              55\n",
       "keywords           25788\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f708c",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e252eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "032fc026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4e61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89aa979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['title'].isnull()].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb190eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = df[['title' , 'subtitle' , 'description' , 'summary' , 'keywords']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3f8e58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:1000 , :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0745c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ec713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765324eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "046e3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transform(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # removing special chars\n",
    "    for i in text:\n",
    "        if i.isalnum() and (i not in stopwords.words('english') and i not in string.punctuation):\n",
    "            i = lemmatizer.lemmatize(i)\n",
    "            y.append(i)\n",
    "#     text = y[:]                 # cloning because the list is mutable so after clearing y text will be cleared\n",
    "    \n",
    "#     y.clear()\n",
    "#     # removing punctuations and stopwords\n",
    "#     for i in text:\n",
    "#         if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "#             y.append(i)\n",
    "#     text = y[:]\n",
    "#     y.clear()\n",
    "    #stemming\n",
    "#     ps = PorterStemmer()\n",
    "#     for i in text:\n",
    "#         y.append(ps.stem(i))\n",
    "    # lemmatizaiton\n",
    " \n",
    "    \n",
    "    return \" \".join(y) # return the list in the form of string    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ebd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = stopwords.words('english')\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    doc = nlp(text.lower())  # Convert text to lowercase and process with spaCy\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and token.text not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff4f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title  done\n",
      "subtitle  done\n",
      "description  done\n",
      "summary  done\n",
      "keywords  done\n"
     ]
    }
   ],
   "source": [
    "for col in text_df.columns:\n",
    "    df[col] = df[col].apply(preprocess_text)\n",
    "    print(col , \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa24d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c545f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the df\n",
    "\n",
    "df.to_csv('transformed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd023e34",
   "metadata": {},
   "source": [
    "## Ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1a2a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24852f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('transformed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb4cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'show_id', 'title', 'link', 'guid', 'subtitle', 'description',\n",
       "       'summary', 'author', 'audio_url', 'audio_file_size', 'audio_mime_type',\n",
       "       'category', 'explicit', 'length', 'pub_date', 'keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dd4e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'show_id', 'title' , 'subtitle', 'description',\n",
    "       'summary', 'author', 'audio_url' , 'category' , 'length']\n",
    "main_df = df[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62df4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['combined_text'] = df[text_df.columns].apply(lambda row : ''.join(row.values.astype(str)) , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22770d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(main_df['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b95bd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names_out() # saving vocabulary and tf-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140ec7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f604d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query , tfidf_matrix , vectorizer):\n",
    "    preprocessed_query = text_transform(query)\n",
    "    query_vector = vectorizer.transform([preprocessed_query])\n",
    "    \n",
    "    similarity_scores = cosine_similarity(query_vector , tfidf_matrix)\n",
    "    top_indices = similarity_scores.argsort()[0][::-1]\n",
    "    \n",
    "    return df.iloc[top_indices[:5]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3070a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       title  \\\n",
      "311       google buy twitter   \n",
      "344        free e form radio   \n",
      "120     edl thing might know   \n",
      "211         storycorps sissy   \n",
      "674  episode tell story edit   \n",
      "\n",
      "                                           description  \\\n",
      "311  p microsoft buy linkedin microsoft planner dro...   \n",
      "344  p episode jesse start explain newfangled techn...   \n",
      "120  mark chris little fun unusual trivium cover te...   \n",
      "211  electrical power plant technology instructor w...   \n",
      "674  heart editing technology even software use edi...   \n",
      "\n",
      "                                                  link  \n",
      "311      http://amplify.libsyn.com/google-buys-twitter  \n",
      "344  http://feedproxy.google.com/~r/collegeyears/~3...  \n",
      "120  http://elementopie.com/feeds/geekrant/?p=episo...  \n",
      "211                                                NaN  \n",
      "674                    http://2reelguys.com/episode-8/  \n"
     ]
    }
   ],
   "source": [
    "query = \"AI technology in podcasts\"\n",
    "search_results = search_query(query, tfidf_matrix, vectorizer)\n",
    "print(search_results[['title', 'description', 'link']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277437b2",
   "metadata": {},
   "source": [
    "## exporting tfidf-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2546164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( tfidf_matrix, open('tfidf-matrix.pkl' , 'wb'))\n",
    "pickle.dump(vectorizer , open('vectorizer.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51d5eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 20:07:56.301 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\windows\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Streamlit interface\n",
    "st.title(\"Search Engine\")\n",
    "query = st.text_input(\"Enter your search query:\")\n",
    "\n",
    "if query:\n",
    "    search_results = search_query(query, tfidf_matrix, vectorizer)\n",
    "    for index, row in search_results.iterrows():\n",
    "        st.write(f\"**Title**: {row['title']}\")\n",
    "        st.write(f\"**Description**: {row['description']}\")\n",
    "        st.write(f\"[Link]({row['link']})\")\n",
    "        st.write(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03c609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
